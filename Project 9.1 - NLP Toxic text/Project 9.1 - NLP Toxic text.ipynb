{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Альтернативное-решиение-с-использованием-Bert\" data-toc-modified-id=\"Альтернативное-решиение-с-использованием-Bert-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Альтернативное решиение с использованием Bert</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tqdm\n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import sys\n",
    "import spacy\n",
    "\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import transformers as ppb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df= pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "except:\n",
    "    df=pd.read_csv('/Users/aleksandrivanov/Downloads/toxic_comments.csv', index_col=0)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159292.000000\n",
       "mean        0.101612\n",
       "std         0.302139\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['toxic'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31069</th>\n",
       "      <td>Death year  a friend has a letter from W.D.M. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155102</th>\n",
       "      <td>You missed one. We can play this game all night</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63484</th>\n",
       "      <td>&gt;&gt;&gt;Nijdam, let me try to turn this problem rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8382</th>\n",
       "      <td>Save your sarcastic little remarks DICK.  Ok D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34775</th>\n",
       "      <td>\"On Tom Waits' \"\"Orphans\"\" album, he includes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29257</th>\n",
       "      <td>\"\\n\\nWhat a waffle. Yep. Its \"\"neither begets ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30317</th>\n",
       "      <td>That's not fair. A majority of the world haven...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131392</th>\n",
       "      <td>It might do me well to think about Czech gramm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133470</th>\n",
       "      <td>\"\\n\\nCan you upload this picture (note the Agg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20249</th>\n",
       "      <td>yeah \\n\\nbut scientology is still a fucking jo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "31069   Death year  a friend has a letter from W.D.M. ...      0\n",
       "155102    You missed one. We can play this game all night      0\n",
       "63484   >>>Nijdam, let me try to turn this problem rou...      0\n",
       "8382    Save your sarcastic little remarks DICK.  Ok D...      1\n",
       "34775   \"On Tom Waits' \"\"Orphans\"\" album, he includes ...      0\n",
       "29257   \"\\n\\nWhat a waffle. Yep. Its \"\"neither begets ...      0\n",
       "30317   That's not fair. A majority of the world haven...      0\n",
       "131392  It might do me well to think about Czech gramm...      0\n",
       "133470  \"\\n\\nCan you upload this picture (note the Agg...      0\n",
       "20249   yeah \\n\\nbut scientology is still a fucking jo...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сильный дисбаланс, 140 тысяч против 20, надо бы исправить позже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text): # токенизация и лемматизация\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemm_list =[wnl.lemmatize(x,get_wordnet_pos(x)) for x in text.split()]\n",
    "    lemm_text = \" \".join(lemm_list)\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizee(text):\n",
    "    doc = nlp(text)\n",
    "    lemm_list = [token.lemma_ for token in doc]\n",
    "    lemm_text = \" \".join(lemm_list)\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text): #очищение текста\n",
    "    clear_text = re.sub(r\"[^a-zA-Z']\", ' ', text)\n",
    "    clear_text = \" \".join(clear_text.split())\n",
    "    return clear_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Очищенный и лемматизированный текст: explanation why the edit make under my username hardcore metallica fan be revert they be not vandalism just closure on some gas after I vote at new york doll fac and please do not remove the template from the talk page since I be retire now\n"
     ]
    }
   ],
   "source": [
    "print(\"Очищенный и лемматизированный текст:\", lemmatizee(clear_text(corpus[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a488c1248c44d48e4eb40a4f320703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['lemma_text']=df['text'].progress_apply( lambda x: lemmatizee(clear_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he match this background colour I be see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man I be really not try to edit war it be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more I can not make any real suggestion on imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there s no actual article for pros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and I really do not think you understand I com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159446  \":::::And for the second time of asking, when ...      0   \n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159449  And it looks like it was actually you who put ...      0   \n",
       "159450  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                               lemma_text  \n",
       "0       explanation why the edit make under my usernam...  \n",
       "1       d'aww he match this background colour I be see...  \n",
       "2       hey man I be really not try to edit war it be ...  \n",
       "3       more I can not make any real suggestion on imp...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159446  and for the second time of ask when your view ...  \n",
       "159447  you should be ashamed of yourself that be a ho...  \n",
       "159448  spitzer umm there s no actual article for pros...  \n",
       "159449  and it look like it be actually you who put on...  \n",
       "159450  and I really do not think you understand I com...  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "text_help = \" \".join(df['lemma_text'])\n",
    "wordcloud = WordCloud().generate(text_help )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    "\n",
    "Так ты его не вывел.  И информативнее строить отдельно для токсичных и нетоксичных\n",
    "    \n",
    "    \n",
    "    \n",
    "    !/opt/conda/bin/python -m pip install wordcloud\n",
    "    from wordcloud import WordCloud\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    df_negative = df[df['toxic'] == 1]\n",
    "    text_cloud = ' '.join(df_negative['text'])\n",
    "    cloud = WordCloud(stopwords=stopwords, max_words=80, collocations=False).generate(text_cloud)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(cloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_negative \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoxic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m text_cloud \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df_negative[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m cloud \u001b[38;5;241m=\u001b[39m WordCloud(stopwords\u001b[38;5;241m=\u001b[39mstopwords, max_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, collocations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mgenerate(text_cloud)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_negative = df[df['toxic'] == 1]\n",
    "text_cloud = ' '.join(df_negative['text'])\n",
    "cloud = WordCloud(stopwords=stopwords, max_words=80, collocations=False).generate(text_cloud)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['toxic'], axis=1)\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleksandrivanov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (127433, 133217)\n"
     ]
    }
   ],
   "source": [
    "corpus = features_train['lemma_text'].values\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=list(stopwords)) \n",
    "tf_idf = count_tf_idf.fit_transform(corpus)\n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " попробуем нашу модель на логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 2.69 s, total: 13.3 s\n",
      "Wall time: 48.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;you&#x27;,\n",
       "                                                                    &#x27;isn&#x27;, &#x27;if&#x27;,\n",
       "                                                                    &#x27;itself&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;into&#x27;,\n",
       "                                                                    &#x27;ve&#x27;,\n",
       "                                                                    &quot;you&#x27;d&quot;,\n",
       "                                                                    &#x27;shouldn&#x27;,\n",
       "                                                                    &quot;she&#x27;s&quot;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &#x27;these&#x27;,\n",
       "                                                                    &#x27;in&#x27;,\n",
       "                                                                    &#x27;than&#x27;,\n",
       "                                                                    &#x27;too&#x27;,\n",
       "                                                                    &#x27;what&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;having&#x27;,\n",
       "                                                                    &#x27;mustn&#x27;,\n",
       "                                                                    &quot;needn&#x27;t&quot;,\n",
       "                                                                    &#x27;to&#x27;, &#x27;any&#x27;,\n",
       "                                                                    &#x27;off&#x27;, &#x27;no&#x27;,\n",
       "                                                                    &#x27;all&#x27;,\n",
       "                                                                    &#x27;very&#x27;,\n",
       "                                                                    &#x27;own&#x27;, ...])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__C&#x27;: [0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
       "                         &#x27;model__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;you&#x27;,\n",
       "                                                                    &#x27;isn&#x27;, &#x27;if&#x27;,\n",
       "                                                                    &#x27;itself&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;into&#x27;,\n",
       "                                                                    &#x27;ve&#x27;,\n",
       "                                                                    &quot;you&#x27;d&quot;,\n",
       "                                                                    &#x27;shouldn&#x27;,\n",
       "                                                                    &quot;she&#x27;s&quot;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &#x27;these&#x27;,\n",
       "                                                                    &#x27;in&#x27;,\n",
       "                                                                    &#x27;than&#x27;,\n",
       "                                                                    &#x27;too&#x27;,\n",
       "                                                                    &#x27;what&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;having&#x27;,\n",
       "                                                                    &#x27;mustn&#x27;,\n",
       "                                                                    &quot;needn&#x27;t&quot;,\n",
       "                                                                    &#x27;to&#x27;, &#x27;any&#x27;,\n",
       "                                                                    &#x27;off&#x27;, &#x27;no&#x27;,\n",
       "                                                                    &#x27;all&#x27;,\n",
       "                                                                    &#x27;very&#x27;,\n",
       "                                                                    &#x27;own&#x27;, ...])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__C&#x27;: [0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
       "                         &#x27;model__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;you&#x27;, &#x27;isn&#x27;, &#x27;if&#x27;, &#x27;itself&#x27;,\n",
       "                                             &#x27;his&#x27;, &quot;couldn&#x27;t&quot;, &#x27;hers&#x27;, &#x27;into&#x27;,\n",
       "                                             &#x27;ve&#x27;, &quot;you&#x27;d&quot;, &#x27;shouldn&#x27;, &quot;she&#x27;s&quot;,\n",
       "                                             &#x27;myself&#x27;, &#x27;couldn&#x27;, &#x27;these&#x27;, &#x27;in&#x27;,\n",
       "                                             &#x27;than&#x27;, &#x27;too&#x27;, &#x27;what&#x27;, &#x27;ourselves&#x27;,\n",
       "                                             &#x27;having&#x27;, &#x27;mustn&#x27;, &quot;needn&#x27;t&quot;, &#x27;to&#x27;,\n",
       "                                             &#x27;any&#x27;, &#x27;off&#x27;, &#x27;no&#x27;, &#x27;all&#x27;, &#x27;very&#x27;,\n",
       "                                             &#x27;own&#x27;, ...])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, random_state=12345))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;you&#x27;, &#x27;isn&#x27;, &#x27;if&#x27;, &#x27;itself&#x27;, &#x27;his&#x27;, &quot;couldn&#x27;t&quot;,\n",
       "                            &#x27;hers&#x27;, &#x27;into&#x27;, &#x27;ve&#x27;, &quot;you&#x27;d&quot;, &#x27;shouldn&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;myself&#x27;, &#x27;couldn&#x27;, &#x27;these&#x27;, &#x27;in&#x27;, &#x27;than&#x27;, &#x27;too&#x27;,\n",
       "                            &#x27;what&#x27;, &#x27;ourselves&#x27;, &#x27;having&#x27;, &#x27;mustn&#x27;, &quot;needn&#x27;t&quot;,\n",
       "                            &#x27;to&#x27;, &#x27;any&#x27;, &#x27;off&#x27;, &#x27;no&#x27;, &#x27;all&#x27;, &#x27;very&#x27;, &#x27;own&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=12345)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words=['you',\n",
       "                                                                    'isn', 'if',\n",
       "                                                                    'itself',\n",
       "                                                                    'his',\n",
       "                                                                    \"couldn't\",\n",
       "                                                                    'hers',\n",
       "                                                                    'into',\n",
       "                                                                    've',\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'shouldn',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'myself',\n",
       "                                                                    'couldn',\n",
       "                                                                    'these',\n",
       "                                                                    'in',\n",
       "                                                                    'than',\n",
       "                                                                    'too',\n",
       "                                                                    'what',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'having',\n",
       "                                                                    'mustn',\n",
       "                                                                    \"needn't\",\n",
       "                                                                    'to', 'any',\n",
       "                                                                    'off', 'no',\n",
       "                                                                    'all',\n",
       "                                                                    'very',\n",
       "                                                                    'own', ...])),\n",
       "                                       ('model',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
       "                         'model__penalty': ['l1', 'l2']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params={'model__C':[.01,.05,.1,.5,1,5,10],\n",
    "           'model__penalty':['l1','l2']}\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('model',LogisticRegression(max_iter = 1000, random_state = 12345))])\n",
    "grid_log = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=params ,scoring='f1')\n",
    "grid_log.fit(features_train['lemma_text'], target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768952556586477\n"
     ]
    }
   ],
   "source": [
    "print(grid_log.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробуем деревянную модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_fr = {'max_depth' : range(1,9),\n",
    "                'n_estimators': range(1, 40)} #я понимаю, что это не лес, а опушка какая-то, но очень долго считает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 4.01 s, total: 14.2 s\n",
      "Wall time: 2min 8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;you&#x27;,\n",
       "                                                                    &#x27;isn&#x27;, &#x27;if&#x27;,\n",
       "                                                                    &#x27;itself&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;into&#x27;,\n",
       "                                                                    &#x27;ve&#x27;,\n",
       "                                                                    &quot;you&#x27;d&quot;,\n",
       "                                                                    &#x27;shouldn&#x27;,\n",
       "                                                                    &quot;she&#x27;s&quot;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &#x27;these&#x27;,\n",
       "                                                                    &#x27;in&#x27;,\n",
       "                                                                    &#x27;than&#x27;,\n",
       "                                                                    &#x27;too&#x27;,\n",
       "                                                                    &#x27;what&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;having&#x27;,\n",
       "                                                                    &#x27;mustn&#x27;,\n",
       "                                                                    &quot;needn&#x27;t&quot;,\n",
       "                                                                    &#x27;to&#x27;, &#x27;any&#x27;,\n",
       "                                                                    &#x27;off&#x27;, &#x27;no&#x27;,\n",
       "                                                                    &#x27;all&#x27;,\n",
       "                                                                    &#x27;very&#x27;,\n",
       "                                                                    &#x27;own&#x27;, ...])),\n",
       "                                       (&#x27;rt&#x27;,\n",
       "                                        RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                               random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;rt__max_depth&#x27;: range(7, 12),\n",
       "                         &#x27;rt__n_estimators&#x27;: range(35, 50)},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;you&#x27;,\n",
       "                                                                    &#x27;isn&#x27;, &#x27;if&#x27;,\n",
       "                                                                    &#x27;itself&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;into&#x27;,\n",
       "                                                                    &#x27;ve&#x27;,\n",
       "                                                                    &quot;you&#x27;d&quot;,\n",
       "                                                                    &#x27;shouldn&#x27;,\n",
       "                                                                    &quot;she&#x27;s&quot;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &#x27;these&#x27;,\n",
       "                                                                    &#x27;in&#x27;,\n",
       "                                                                    &#x27;than&#x27;,\n",
       "                                                                    &#x27;too&#x27;,\n",
       "                                                                    &#x27;what&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;having&#x27;,\n",
       "                                                                    &#x27;mustn&#x27;,\n",
       "                                                                    &quot;needn&#x27;t&quot;,\n",
       "                                                                    &#x27;to&#x27;, &#x27;any&#x27;,\n",
       "                                                                    &#x27;off&#x27;, &#x27;no&#x27;,\n",
       "                                                                    &#x27;all&#x27;,\n",
       "                                                                    &#x27;very&#x27;,\n",
       "                                                                    &#x27;own&#x27;, ...])),\n",
       "                                       (&#x27;rt&#x27;,\n",
       "                                        RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                               random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;rt__max_depth&#x27;: range(7, 12),\n",
       "                         &#x27;rt__n_estimators&#x27;: range(35, 50)},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;you&#x27;, &#x27;isn&#x27;, &#x27;if&#x27;, &#x27;itself&#x27;,\n",
       "                                             &#x27;his&#x27;, &quot;couldn&#x27;t&quot;, &#x27;hers&#x27;, &#x27;into&#x27;,\n",
       "                                             &#x27;ve&#x27;, &quot;you&#x27;d&quot;, &#x27;shouldn&#x27;, &quot;she&#x27;s&quot;,\n",
       "                                             &#x27;myself&#x27;, &#x27;couldn&#x27;, &#x27;these&#x27;, &#x27;in&#x27;,\n",
       "                                             &#x27;than&#x27;, &#x27;too&#x27;, &#x27;what&#x27;, &#x27;ourselves&#x27;,\n",
       "                                             &#x27;having&#x27;, &#x27;mustn&#x27;, &quot;needn&#x27;t&quot;, &#x27;to&#x27;,\n",
       "                                             &#x27;any&#x27;, &#x27;off&#x27;, &#x27;no&#x27;, &#x27;all&#x27;, &#x27;very&#x27;,\n",
       "                                             &#x27;own&#x27;, ...])),\n",
       "                (&#x27;rt&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                        random_state=12345))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;you&#x27;, &#x27;isn&#x27;, &#x27;if&#x27;, &#x27;itself&#x27;, &#x27;his&#x27;, &quot;couldn&#x27;t&quot;,\n",
       "                            &#x27;hers&#x27;, &#x27;into&#x27;, &#x27;ve&#x27;, &quot;you&#x27;d&quot;, &#x27;shouldn&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;myself&#x27;, &#x27;couldn&#x27;, &#x27;these&#x27;, &#x27;in&#x27;, &#x27;than&#x27;, &#x27;too&#x27;,\n",
       "                            &#x27;what&#x27;, &#x27;ourselves&#x27;, &#x27;having&#x27;, &#x27;mustn&#x27;, &quot;needn&#x27;t&quot;,\n",
       "                            &#x27;to&#x27;, &#x27;any&#x27;, &#x27;off&#x27;, &#x27;no&#x27;, &#x27;all&#x27;, &#x27;very&#x27;, &#x27;own&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words=['you',\n",
       "                                                                    'isn', 'if',\n",
       "                                                                    'itself',\n",
       "                                                                    'his',\n",
       "                                                                    \"couldn't\",\n",
       "                                                                    'hers',\n",
       "                                                                    'into',\n",
       "                                                                    've',\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'shouldn',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'myself',\n",
       "                                                                    'couldn',\n",
       "                                                                    'these',\n",
       "                                                                    'in',\n",
       "                                                                    'than',\n",
       "                                                                    'too',\n",
       "                                                                    'what',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'having',\n",
       "                                                                    'mustn',\n",
       "                                                                    \"needn't\",\n",
       "                                                                    'to', 'any',\n",
       "                                                                    'off', 'no',\n",
       "                                                                    'all',\n",
       "                                                                    'very',\n",
       "                                                                    'own', ...])),\n",
       "                                       ('rt',\n",
       "                                        RandomForestClassifier(class_weight='balanced',\n",
       "                                                               random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rt__max_depth': range(7, 12),\n",
       "                         'rt__n_estimators': range(35, 50)},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('rt',RandomForestClassifier(random_state=12345, class_weight = 'balanced'))])\n",
    "parameters_fr = {'rt__max_depth' : range(7,12),\n",
    "                'rt__n_estimators': range(35, 50)} #я понимаю, что это не лес, а опушка какая-то, но очень долго считает\n",
    "fr_grid_model = GridSearchCV(pipeline, cv=3, n_jobs=-1, param_grid=parameters_fr, scoring='f1')\n",
    "fr_grid_model.fit(features_train['lemma_text'], target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rt__max_depth': 11, 'rt__n_estimators': 49}\n",
      "0.3712507980966661\n"
     ]
    }
   ],
   "source": [
    "print(fr_grid_model.best_params_)\n",
    "print(fr_grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 52s, sys: 9.57 s, total: 26min 1s\n",
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catboost = CatBoostClassifier(eval_metric = 'F1', verbose = False)\n",
    "cat_m = catboost.fit(tf_idf, target_train, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learn': {'Logloss': 0.10282271617263541, 'F1': 0.8008544346046016}}\n"
     ]
    }
   ],
   "source": [
    "print(cat_m.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "param_grid = {\n",
    "    'num_leaves': [10, 20, 31, 40, 50],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [10, 20]\n",
    "  }\n",
    "# grid_lgb = GridSearchCV(estimator=LGBMClassifier(), param_grid=param_grid, cv=3, scoring = 'f1')\n",
    "# grid_lgb.fit(tf_idf, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.4 s, sys: 8.6 s, total: 42 s\n",
      "Wall time: 3min 5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;you&#x27;,\n",
       "                                                                    &#x27;isn&#x27;, &#x27;if&#x27;,\n",
       "                                                                    &#x27;itself&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;into&#x27;,\n",
       "                                                                    &#x27;ve&#x27;,\n",
       "                                                                    &quot;you&#x27;d&quot;,\n",
       "                                                                    &#x27;shouldn&#x27;,\n",
       "                                                                    &quot;she&#x27;s&quot;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &#x27;these&#x27;,\n",
       "                                                                    &#x27;in&#x27;,\n",
       "                                                                    &#x27;than&#x27;,\n",
       "                                                                    &#x27;too&#x27;,\n",
       "                                                                    &#x27;what&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;having&#x27;,\n",
       "                                                                    &#x27;mustn&#x27;,\n",
       "                                                                    &quot;needn&#x27;t&quot;,\n",
       "                                                                    &#x27;to&#x27;, &#x27;any&#x27;,\n",
       "                                                                    &#x27;off&#x27;, &#x27;no&#x27;,\n",
       "                                                                    &#x27;all&#x27;,\n",
       "                                                                    &#x27;very&#x27;,\n",
       "                                                                    &#x27;own&#x27;, ...])),\n",
       "                                       (&#x27;lgb&#x27;,\n",
       "                                        LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                       random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;lgb__learning_rate&#x27;: [0.05, 0.1],\n",
       "                         &#x27;lgb__n_estimators&#x27;: [10, 20],\n",
       "                         &#x27;lgb__num_leaves&#x27;: [10, 20, 31, 40, 50]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;you&#x27;,\n",
       "                                                                    &#x27;isn&#x27;, &#x27;if&#x27;,\n",
       "                                                                    &#x27;itself&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;into&#x27;,\n",
       "                                                                    &#x27;ve&#x27;,\n",
       "                                                                    &quot;you&#x27;d&quot;,\n",
       "                                                                    &#x27;shouldn&#x27;,\n",
       "                                                                    &quot;she&#x27;s&quot;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &#x27;these&#x27;,\n",
       "                                                                    &#x27;in&#x27;,\n",
       "                                                                    &#x27;than&#x27;,\n",
       "                                                                    &#x27;too&#x27;,\n",
       "                                                                    &#x27;what&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;having&#x27;,\n",
       "                                                                    &#x27;mustn&#x27;,\n",
       "                                                                    &quot;needn&#x27;t&quot;,\n",
       "                                                                    &#x27;to&#x27;, &#x27;any&#x27;,\n",
       "                                                                    &#x27;off&#x27;, &#x27;no&#x27;,\n",
       "                                                                    &#x27;all&#x27;,\n",
       "                                                                    &#x27;very&#x27;,\n",
       "                                                                    &#x27;own&#x27;, ...])),\n",
       "                                       (&#x27;lgb&#x27;,\n",
       "                                        LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                       random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;lgb__learning_rate&#x27;: [0.05, 0.1],\n",
       "                         &#x27;lgb__n_estimators&#x27;: [10, 20],\n",
       "                         &#x27;lgb__num_leaves&#x27;: [10, 20, 31, 40, 50]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;you&#x27;, &#x27;isn&#x27;, &#x27;if&#x27;, &#x27;itself&#x27;,\n",
       "                                             &#x27;his&#x27;, &quot;couldn&#x27;t&quot;, &#x27;hers&#x27;, &#x27;into&#x27;,\n",
       "                                             &#x27;ve&#x27;, &quot;you&#x27;d&quot;, &#x27;shouldn&#x27;, &quot;she&#x27;s&quot;,\n",
       "                                             &#x27;myself&#x27;, &#x27;couldn&#x27;, &#x27;these&#x27;, &#x27;in&#x27;,\n",
       "                                             &#x27;than&#x27;, &#x27;too&#x27;, &#x27;what&#x27;, &#x27;ourselves&#x27;,\n",
       "                                             &#x27;having&#x27;, &#x27;mustn&#x27;, &quot;needn&#x27;t&quot;, &#x27;to&#x27;,\n",
       "                                             &#x27;any&#x27;, &#x27;off&#x27;, &#x27;no&#x27;, &#x27;all&#x27;, &#x27;very&#x27;,\n",
       "                                             &#x27;own&#x27;, ...])),\n",
       "                (&#x27;lgb&#x27;,\n",
       "                 LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;you&#x27;, &#x27;isn&#x27;, &#x27;if&#x27;, &#x27;itself&#x27;, &#x27;his&#x27;, &quot;couldn&#x27;t&quot;,\n",
       "                            &#x27;hers&#x27;, &#x27;into&#x27;, &#x27;ve&#x27;, &quot;you&#x27;d&quot;, &#x27;shouldn&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;myself&#x27;, &#x27;couldn&#x27;, &#x27;these&#x27;, &#x27;in&#x27;, &#x27;than&#x27;, &#x27;too&#x27;,\n",
       "                            &#x27;what&#x27;, &#x27;ourselves&#x27;, &#x27;having&#x27;, &#x27;mustn&#x27;, &quot;needn&#x27;t&quot;,\n",
       "                            &#x27;to&#x27;, &#x27;any&#x27;, &#x27;off&#x27;, &#x27;no&#x27;, &#x27;all&#x27;, &#x27;very&#x27;, &#x27;own&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=12345)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words=['you',\n",
       "                                                                    'isn', 'if',\n",
       "                                                                    'itself',\n",
       "                                                                    'his',\n",
       "                                                                    \"couldn't\",\n",
       "                                                                    'hers',\n",
       "                                                                    'into',\n",
       "                                                                    've',\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'shouldn',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'myself',\n",
       "                                                                    'couldn',\n",
       "                                                                    'these',\n",
       "                                                                    'in',\n",
       "                                                                    'than',\n",
       "                                                                    'too',\n",
       "                                                                    'what',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'having',\n",
       "                                                                    'mustn',\n",
       "                                                                    \"needn't\",\n",
       "                                                                    'to', 'any',\n",
       "                                                                    'off', 'no',\n",
       "                                                                    'all',\n",
       "                                                                    'very',\n",
       "                                                                    'own', ...])),\n",
       "                                       ('lgb',\n",
       "                                        LGBMClassifier(class_weight='balanced',\n",
       "                                                       random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lgb__learning_rate': [0.05, 0.1],\n",
       "                         'lgb__n_estimators': [10, 20],\n",
       "                         'lgb__num_leaves': [10, 20, 31, 40, 50]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('lgb',LGBMClassifier(random_state=12345, class_weight = 'balanced'))])\n",
    "param_grid = {\n",
    "    'lgb__num_leaves': [10, 20, 31, 40, 50],\n",
    "    'lgb__learning_rate': [0.05, 0.1],\n",
    "    'lgb__n_estimators': [10, 20]}\n",
    "grid_lgb = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=param_grid, scoring='f1')\n",
    "grid_lgb.fit(features_train['lemma_text'], target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__learning_rate': 0.1, 'lgb__n_estimators': 20, 'lgb__num_leaves': 50}\n",
      "0.7037335709405599\n"
     ]
    }
   ],
   "source": [
    "print(grid_lgb.best_params_)\n",
    "print(grid_lgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "params_xgb = {\n",
    "        'n_estimators': [10,50],\n",
    "        'max_depth': [3, 8],\n",
    "        'eta': [0.5, 1]\n",
    "        }\n",
    "# grid_xgb = GridSearchCV(XGBClassifier(), params_xgb, n_jobs=-1, scoring = 'f1', cv = 3)\n",
    "\n",
    "# grid_xgb.fit(tf_idf, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:01:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "CPU times: user 1min 37s, sys: 7.17 s, total: 1min 44s\n",
      "Wall time: 4min 18s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;you&#x27;,\n",
       "                                                                    &#x27;isn&#x27;, &#x27;if&#x27;,\n",
       "                                                                    &#x27;itself&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;into&#x27;,\n",
       "                                                                    &#x27;ve&#x27;,\n",
       "                                                                    &quot;you&#x27;d&quot;,\n",
       "                                                                    &#x27;shouldn&#x27;,\n",
       "                                                                    &quot;she&#x27;s&quot;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &#x27;these&#x27;,\n",
       "                                                                    &#x27;in&#x27;,\n",
       "                                                                    &#x27;than&#x27;,\n",
       "                                                                    &#x27;too&#x27;,\n",
       "                                                                    &#x27;what&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;having&#x27;,\n",
       "                                                                    &#x27;mustn&#x27;,\n",
       "                                                                    &quot;needn&#x27;t&quot;,\n",
       "                                                                    &#x27;to&#x27;, &#x27;any&#x27;,\n",
       "                                                                    &#x27;off&#x27;, &#x27;no&#x27;,\n",
       "                                                                    &#x27;all&#x27;,\n",
       "                                                                    &#x27;very&#x27;,\n",
       "                                                                    &#x27;own&#x27;, ...])),\n",
       "                                       (&#x27;xgb&#x27;,\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booste...\n",
       "                                                      max_bin=None,\n",
       "                                                      max_cat_threshold=None,\n",
       "                                                      max_cat_to_onehot=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      max_leaves=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;xgb__eta&#x27;: [0.5, 1], &#x27;xgb__max_depth&#x27;: [3, 8],\n",
       "                         &#x27;xgb__n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;you&#x27;,\n",
       "                                                                    &#x27;isn&#x27;, &#x27;if&#x27;,\n",
       "                                                                    &#x27;itself&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;into&#x27;,\n",
       "                                                                    &#x27;ve&#x27;,\n",
       "                                                                    &quot;you&#x27;d&quot;,\n",
       "                                                                    &#x27;shouldn&#x27;,\n",
       "                                                                    &quot;she&#x27;s&quot;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &#x27;these&#x27;,\n",
       "                                                                    &#x27;in&#x27;,\n",
       "                                                                    &#x27;than&#x27;,\n",
       "                                                                    &#x27;too&#x27;,\n",
       "                                                                    &#x27;what&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;having&#x27;,\n",
       "                                                                    &#x27;mustn&#x27;,\n",
       "                                                                    &quot;needn&#x27;t&quot;,\n",
       "                                                                    &#x27;to&#x27;, &#x27;any&#x27;,\n",
       "                                                                    &#x27;off&#x27;, &#x27;no&#x27;,\n",
       "                                                                    &#x27;all&#x27;,\n",
       "                                                                    &#x27;very&#x27;,\n",
       "                                                                    &#x27;own&#x27;, ...])),\n",
       "                                       (&#x27;xgb&#x27;,\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booste...\n",
       "                                                      max_bin=None,\n",
       "                                                      max_cat_threshold=None,\n",
       "                                                      max_cat_to_onehot=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      max_leaves=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;xgb__eta&#x27;: [0.5, 1], &#x27;xgb__max_depth&#x27;: [3, 8],\n",
       "                         &#x27;xgb__n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;you&#x27;, &#x27;isn&#x27;, &#x27;if&#x27;, &#x27;itself&#x27;,\n",
       "                                             &#x27;his&#x27;, &quot;couldn&#x27;t&quot;, &#x27;hers&#x27;, &#x27;into&#x27;,\n",
       "                                             &#x27;ve&#x27;, &quot;you&#x27;d&quot;, &#x27;shouldn&#x27;, &quot;she&#x27;s&quot;,\n",
       "                                             &#x27;myself&#x27;, &#x27;couldn&#x27;, &#x27;these&#x27;, &#x27;in&#x27;,\n",
       "                                             &#x27;than&#x27;, &#x27;too&#x27;, &#x27;what&#x27;, &#x27;ourselves&#x27;,\n",
       "                                             &#x27;having&#x27;, &#x27;mustn&#x27;, &quot;needn&#x27;t&quot;, &#x27;to&#x27;,\n",
       "                                             &#x27;any&#x27;, &#x27;off&#x27;, &#x27;no&#x27;, &#x27;all&#x27;, &#x27;very&#x27;,\n",
       "                                             &#x27;own&#x27;, ...])),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               class_...\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;you&#x27;, &#x27;isn&#x27;, &#x27;if&#x27;, &#x27;itself&#x27;, &#x27;his&#x27;, &quot;couldn&#x27;t&quot;,\n",
       "                            &#x27;hers&#x27;, &#x27;into&#x27;, &#x27;ve&#x27;, &quot;you&#x27;d&quot;, &#x27;shouldn&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;myself&#x27;, &#x27;couldn&#x27;, &#x27;these&#x27;, &#x27;in&#x27;, &#x27;than&#x27;, &#x27;too&#x27;,\n",
       "                            &#x27;what&#x27;, &#x27;ourselves&#x27;, &#x27;having&#x27;, &#x27;mustn&#x27;, &quot;needn&#x27;t&quot;,\n",
       "                            &#x27;to&#x27;, &#x27;any&#x27;, &#x27;off&#x27;, &#x27;no&#x27;, &#x27;all&#x27;, &#x27;very&#x27;, &#x27;own&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              class_weight=&#x27;balanced&#x27;, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words=['you',\n",
       "                                                                    'isn', 'if',\n",
       "                                                                    'itself',\n",
       "                                                                    'his',\n",
       "                                                                    \"couldn't\",\n",
       "                                                                    'hers',\n",
       "                                                                    'into',\n",
       "                                                                    've',\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'shouldn',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'myself',\n",
       "                                                                    'couldn',\n",
       "                                                                    'these',\n",
       "                                                                    'in',\n",
       "                                                                    'than',\n",
       "                                                                    'too',\n",
       "                                                                    'what',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'having',\n",
       "                                                                    'mustn',\n",
       "                                                                    \"needn't\",\n",
       "                                                                    'to', 'any',\n",
       "                                                                    'off', 'no',\n",
       "                                                                    'all',\n",
       "                                                                    'very',\n",
       "                                                                    'own', ...])),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booste...\n",
       "                                                      max_bin=None,\n",
       "                                                      max_cat_threshold=None,\n",
       "                                                      max_cat_to_onehot=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      max_leaves=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'xgb__eta': [0.5, 1], 'xgb__max_depth': [3, 8],\n",
       "                         'xgb__n_estimators': [10, 50, 100]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('xgb',XGBClassifier(random_state=12345))])\n",
    "params_xgb = {\n",
    "        'xgb__n_estimators': [10,50, 100],\n",
    "        'xgb__max_depth': [3, 8],\n",
    "        'xgb__eta': [0.5, 1]\n",
    "        }\n",
    "grid_xgb = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=params_xgb, scoring='f1')\n",
    "grid_xgb.fit(features_train['lemma_text'], target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xgb__eta': 0.5, 'xgb__max_depth': 8, 'xgb__n_estimators': 100}\n",
      "0.7599711744417805\n"
     ]
    }
   ],
   "source": [
    "print(grid_xgb.best_params_)\n",
    "print(grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "лучший показатель получился на обычном catboost, единственное, я не совсем с ним понял, есть ли там встроенная кросс валидация? проверим нашу наилучшую модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleksandrivanov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "corpus_test = features_test['lemma_text'].values\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "#count_tf_idf_test = TfidfVectorizer(stop_words=list(stopwords)) \n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_predict = cat_m.predict (tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565248480514836\n"
     ]
    }
   ],
   "source": [
    "print (f1_score(target_test, cat_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие выводы:\n",
    "Были проведены следующие этапы обработки/подготовки данных:\n",
    "1. Осмотр датасета\n",
    "2. Проверка на пропуски, аномалии, отклонения, данные подготовлены\n",
    "3. Созданы функции для очистки данных и лемматизации данных\n",
    "4. Далее данные разбиты на тест и трейн\n",
    "5. Далее выполнена веторизация данных\n",
    "6. Проведено обучение на нескольких вариантах моделей, лучшшее значение получилось на моделе Catboost, проверили её на тестовой выбокре и получили значение f1 0.75, что соответствует требованиям заказчика"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 47,
    "start_time": "2023-03-13T15:17:41.085Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-13T15:17:46.599Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
